{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bayes(train_file):\n",
    "    file = open(train_file, 'r')\n",
    "\n",
    "    tweets = file.readlines()\n",
    "    tweets = [re.sub('\\n', '', tweet) for tweet in tweets]\n",
    "\n",
    "    targets = [tweet.split()[0] for tweet in tweets]\n",
    "    text = [tweet.lower().split()[1:] for tweet in tweets]\n",
    "\n",
    "    loc_word_dict = {}\n",
    "    for i in range(len(targets)):\n",
    "        for word in text[i]:\n",
    "            if targets[i] in loc_word_dict.keys():\n",
    "                if word in loc_word_dict[targets[i]].keys():\n",
    "                    loc_word_dict[targets[i]][word] += 1\n",
    "                else:\n",
    "                    loc_word_dict[targets[i]][word] = 1\n",
    "            else:\n",
    "                loc_word_dict[targets[i]] = {word: 1}\n",
    "\n",
    "    word_loc_dict = {}\n",
    "    for i in range(len(targets)):\n",
    "        for word in text[i]:\n",
    "            if word in word_loc_dict.keys():\n",
    "                if targets[i] in word_loc_dict[word].keys():\n",
    "                    word_loc_dict[word][targets[i]] += 1\n",
    "                else:\n",
    "                    word_loc_dict[word][targets[i]] = 1\n",
    "            else:\n",
    "                word_loc_dict[word] = {targets[i]: 1}\n",
    "\n",
    "    p_L = Counter(targets)\n",
    "\n",
    "    for value in loc_word_dict.values():\n",
    "        total = sum(value.values())\n",
    "        for key in value.keys():\n",
    "            value[key] = value[key] / total\n",
    "\n",
    "    word_loc_dict2 = {}\n",
    "    for key in word_loc_dict.keys():\n",
    "        if sum(word_loc_dict[key].values()) >= 5:\n",
    "            word_loc_dict2[key] = word_loc_dict[key]\n",
    "\n",
    "    for value in word_loc_dict2.values():\n",
    "        total = sum(value.values())\n",
    "        for key in value.keys():\n",
    "            value[key] = [value[key] / total, value[key]]\n",
    "    \n",
    "    total = sum(p_L.values())\n",
    "    for key in p_L.keys():\n",
    "        p_L[key] = p_L[key] / total\n",
    "\n",
    "    top_words = {}\n",
    "    for loc in set(targets):\n",
    "        words = []\n",
    "        for word in word_loc_dict2.keys():\n",
    "            if loc in word_loc_dict2[word].keys():\n",
    "                words.append([word, word_loc_dict2[word][loc]])\n",
    "        words = sorted(words, key = lambda x: (x[1][0], x[1][1]), reverse = True)[0:5]\n",
    "        words = [word[0] for word in words]\n",
    "        top_words[loc] = words\n",
    "\n",
    "    for key in top_words.keys():\n",
    "            ws = ', '.join(top_words[key])\n",
    "            out = f'The top 5 words for {key} are: {ws}'\n",
    "            print(out)\n",
    "    \n",
    "\n",
    "    return loc_word_dict, p_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_file(test_file):\n",
    "    file = open(test_file, 'r')\n",
    "\n",
    "    tweets = file.readlines()\n",
    "    tweets = [re.sub('\\n', '', tweet) for tweet in tweets]\n",
    "\n",
    "    targets = [tweet.split()[0] for tweet in tweets]\n",
    "    text = [' '.join(tweet.split()[1:]) for tweet in tweets]\n",
    "\n",
    "    return (targets, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_one_target(test_tweet, target, loc_word_dict, p_L):\n",
    "    tokenized_tweet = test_tweet.lower().split()\n",
    "    score = math.log(p_L[target])\n",
    "    for token in tokenized_tweet:\n",
    "        if token in loc_word_dict[target].keys():\n",
    "            score += math.log(loc_word_dict[target][token])\n",
    "        else:\n",
    "            score += math.log(1 / 100000)\n",
    "    return (target, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_test(test_tweet, targets, loc_word_dict, p_L):\n",
    "    best_score = -1000000000000000\n",
    "    best_target = ''\n",
    "    for loc in targets:\n",
    "        pos_target, pos_score = test_one_target(test_tweet, loc, loc_word_dict, p_L)\n",
    "        if pos_score > best_score:\n",
    "            best_score = pos_score\n",
    "            best_target = pos_target\n",
    "    return best_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The top 5 words for Manhattan,_NY are: ny), #newyork,, (#newyork,, ny?, cleared:\nThe top 5 words for Atlanta,_GA are: #atlanta,, atlanta,, georgia, (#atlanta,, ga?\nThe top 5 words for Los_Angeles,_CA are: angeles,, #losangeles,, dodger, (#losangeles,, #dodgers\nThe top 5 words for Toronto,_Ontario are: toronto,, trucks), #toronto, #toronto,, b/w\nThe top 5 words for Philadelphia,_PA are: philadelphia,, #philadelphia,, pa), philadelphia, phillies\nThe top 5 words for Chicago,_IL are: chicago,, #chicago,, illinois, (#chicago,, il?\nThe top 5 words for Boston,_MA are: #boston,, ma), massachusetts, ma?, (#boston,\nThe top 5 words for Orlando,_FL are: #orlpol, #opd, #orlando,, fl, orlando,\nThe top 5 words for San_Francisco,_CA are: francisco,, #sanfrancisco,, (#sanfrancisco,, #sf, fran\nThe top 5 words for Washington,_DC are: washington,, #washington,, dc), d.c., (#washington,\nThe top 5 words for San_Diego,_CA are: diego,, (#sandiego,, petco, jolla, #seaworld\nThe top 5 words for Houston,_TX are: #houston,, houston,, tx), (#houston,, beds,\n"
     ]
    }
   ],
   "source": [
    "loc_word_dict, p_L = train_bayes('tweets.train.clean.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets, test_text = read_test_file('tweets.test1.clean.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.632\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "predictions = []\n",
    "for i in range(len(test_text)):\n",
    "    prediction = bayes_test(test_text[i], set(test_targets), loc_word_dict, p_L)\n",
    "    predictions.append((prediction, test_targets[i], test_text[i]))\n",
    "    total += 1\n",
    "    if prediction == test_targets[i]:\n",
    "        correct += 1\n",
    "    \n",
    "score = correct / total\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}